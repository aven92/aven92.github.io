
MongoDB分片搭建
# 1. 环境

	$ cat /etc/redhat-release 
	CentOS Linux release 7.0.1406 (Core) 
	$ uname -a
	Linux zhaopin-2-201 3.10.0-123.el7.x86_64 #1 SMP Mon Jun 30 12:09:22 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux
	$ mongo --version
	MongoDB shell version: 3.0.6

	node1: 172.30.2.201
	node2: 172.30.2.202
	node3: 172.30.2.203

# 2. 配置 Shard Server

在 3 个节点分别执行:

## (1) 创建目录

	$ sudo mkdir -p /data/mongodb/{sh0,sh1}/{data,backup,log,conf}

## (2) 准备配置文件

第一个分片:

	$ sudo vim /data/mongodb/sh0/conf/mongodb.conf
	# base
	port = 27010
	maxConns = 800 
	filePermissions = 0700
	fork = true
	noauth = true
	directoryperdb = true
	dbpath = /data/mongodb/sh0/data
	pidfilepath = /data/mongodb/sh0/data/mongodb.pid
	oplogSize = 10
	journal = true
	# security
	nohttpinterface = true
	rest = false
	# log 
	logpath = /data/mongodb/sh0/log/mongodb.log
	logRotate = rename
	logappend = true
	slowms = 50
	replSet = sh0 
	shardsvr = true

第二个分片:

	$ sudo vim /data/mongodb/sh1/conf/mongodb.conf
	# base
	port = 27011
	maxConns = 800 
	filePermissions = 0700
	fork = true
	noauth = true
	directoryperdb = true
	dbpath = /data/mongodb/sh1/data
	pidfilepath = /data/mongodb/sh1/data/mongodb.pid
	oplogSize = 10
	journal = true
	# security
	nohttpinterface = true
	rest = false
	# log
	logpath = /data/mongodb/sh1/log/mongodb.log
	logRotate = rename
	logappend = true
	slowms = 50
	replSet = sh1
	shardsvr = true

## (3) 启动 Shard Server

	$ sudo /opt/mongodb/bin/mongod --config /data/mongodb/sh0/conf/mongodb.conf
	about to fork child process, waiting until server is ready for connections.
	forked process: 41492
	child process started successfully, parent exiting
	$ sudo /opt/mongodb/bin/mongod --config /data/mongodb/sh1/conf/mongodb.conf
	about to fork child process, waiting until server is ready for connections.
	forked process: 41509
	child process started successfully, parent exiting
	$ ps aux | grep mongo | grep -v grep
	root     41492  0.5  0.0 518016 54604 ?        Sl   10:09   0:00 /opt/mongodb/bin/mongod --config /data/mongodb/conf/sh0/mongodb.conf
	root     41509  0.5  0.0 516988 51824 ?        Sl   10:09   0:00 /opt/mongodb/bin/mongod --config /data/mongodb/conf/sh1/mongodb.conf
	$ mongo --port 27010
	MongoDB shell version: 3.0.6
	connecting to: 127.0.0.1:27010/test
	>
	bye
	$ mongo --port 27011
	MongoDB shell version: 3.0.6
	connecting to: 127.0.0.1:27011/test
	>
	bye

# 3.配置 Config Server

在 3 个节点分别执行:
## (1) 创建目录

	$ sudo mkdir -p /data/mongodb/cf0/{data,backup,log,conf}

## (2) 准备配置文件

	$ sudo vim /data/mongodb/cf0/conf/config.conf
	# base
	port = 27000
	maxConns = 800
	filePermissions = 0700
	fork = true
	noauth = true
	directoryperdb = true
	dbpath = /data/mongodb/cf0/data
	pidfilepath = /data/mongodb/cf0/data/config.pid
	oplogSize = 10
	journal = true
	# security
	nohttpinterface = true
	rest = false
	# log
	logpath = /data/mongodb/cf0/log/config.log
	logRotate = rename
	logappend = true
	slowms = 50
	configsvr = true

## (3) 启动

	$ sudo /opt/mongodb/bin/mongod --config /data/mongodb/cf0/conf/config.conf
	about to fork child process, waiting until server is ready for connections.
	forked process: 41759
	child process started successfully, parent exiting
	$ ps aux | grep mongo | grep -v grep
	root     41492  0.3  0.0 518016 54728 ?        Sl   10:09   0:06 /opt/mongodb/bin/mongod --config /data/mongodb/sh0/conf/mongodb.conf
	root     41509  0.3  0.0 518016 54760 ?        Sl   10:09   0:06 /opt/mongodb/bin/mongod --config /data/mongodb/sh1/conf/mongodb.conf
	root     41855  0.4  0.0 467828 51684 ?        Sl   10:25   0:03 /opt/mongodb/bin/mongod --config /data/mongodb/cf0/conf/config.conf

## 4. 配置 Query Routers

在 3 个节点分别执行:
## (1) 创建目录

	$ sudo mkdir -p /data/mongodb/ms0/{data,backup,log,conf}

## (2) 准备配置文件

	$ sudo vim /data/mongodb/ms0/conf/mongos.conf
	# base
	port = 30000
	maxConns = 800
	filePermissions = 0700
	fork = true
	pidfilepath = /data/mongodb/ms0/data/mongos.pid
	# log
	logpath = /data/mongodb/ms0/log/mongos.log
	logRotate = rename
	logappend = true
	configdb = 172.30.2.201:27000,172.30.2.202:27000,172.30.2.203:27000

## (3) 启动

	$ sudo /opt/mongodb/bin/mongos --config /data/mongodb/ms0/conf/mongos.conf
	about to fork child process, waiting until server is ready for connections.
	forked process: 42233
	child process started successfully, parent exiting
	$ ps aux | grep mongo | grep -v grep
	root     41492  0.3  0.0 518016 54728 ?        Sl   10:09   0:06 /opt/mongodb/bin/mongod --config /data/mongodb/sh0/conf/mongodb.conf
	root     41509  0.3  0.0 518016 54760 ?        Sl   10:09   0:07 /opt/mongodb/bin/mongod --config /data/mongodb/sh1/conf/mongodb.conf
	root     41855  0.4  0.0 546724 37812 ?        Sl   10:25   0:03 /opt/mongodb/bin/mongod --config /data/mongodb/cf0/conf/config.conf
	root     42233  0.5  0.0 233536 10188 ?        Sl   10:38   0:00 /opt/mongodb/bin/mongos --config /data/mongodb/ms0/conf/mongos.conf

# 5. 初始化副本集

配置副本集的好处是为了高可用，配置单节点是我自己为了节省时间，后续添加节点和副本集的操作一样，分片的配置不需要修改,在任何一个节点执行，这里在 node1 上执行

分片一:

	$ mongo --port 27010
	MongoDB shell version: 3.0.6
	connecting to: 127.0.0.1:27010/test
	> use admin
	switched to db admin
	> cfg={_id:"sh0", members:[ {_id:0,host:"172.30.2.201:27010"}, {_id:1,host:"172.30.2.202:27010"}, {_id:2,host:"172.30.2.203:27010"} ] }
	{
	        "_id" : "sh0",
	        "members" : [
	                {
	                        "_id" : 0,
	                        "host" : "172.30.2.201:27010"
	                },
	                {
	                        "_id" : 1,
	                        "host" : "172.30.2.202:27010"
	                },
	                {
	                        "_id" : 2,
	                        "host" : "172.30.2.203:27010"
	                }
	        ]
	}
	> rs.initiate( cfg );
	{ "ok" : 1 }
	sh0:OTHER> rs.status()
	{
	        "set" : "sh0",
	        "date" : ISODate("2015-10-23T05:33:31.920Z"),
	        "myState" : 1,
	        "members" : [
	                {
	                        "_id" : 0,
	                        "name" : "172.30.2.201:27010",
	                        "health" : 1,
	                        "state" : 1,
	                        "stateStr" : "PRIMARY",
	                        "uptime" : 270,
	                        "optime" : Timestamp(1445578404, 1),
	                        "optimeDate" : ISODate("2015-10-23T05:33:24Z"),
	                        "electionTime" : Timestamp(1445578408, 1),
	                        "electionDate" : ISODate("2015-10-23T05:33:28Z"),
	                        "configVersion" : 1,
	                        "self" : true
	                },
	                {
	                        "_id" : 1,
	                        "name" : "172.30.2.202:27010",
	                        "health" : 1,
	                        "state" : 5,
	                        "stateStr" : "STARTUP2",
	                        "uptime" : 7,
	                        "optime" : Timestamp(0, 0),
	                        "optimeDate" : ISODate("1970-01-01T00:00:00Z"),
	                        "lastHeartbeat" : ISODate("2015-10-23T05:33:30.289Z"),
	                        "lastHeartbeatRecv" : ISODate("2015-10-23T05:33:30.295Z"),
	                        "pingMs" : 1,
	                        "configVersion" : 1
	                },
	                {
	                        "_id" : 2,
	                        "name" : "172.30.2.203:27010",
	                        "health" : 1,
	                        "state" : 5,
	                        "stateStr" : "STARTUP2",
	                        "uptime" : 7,
	                        "optime" : Timestamp(0, 0),
	                        "optimeDate" : ISODate("1970-01-01T00:00:00Z"),
	                        "lastHeartbeat" : ISODate("2015-10-23T05:33:30.289Z"),
	                        "lastHeartbeatRecv" : ISODate("2015-10-23T05:33:30.293Z"),
	                        "pingMs" : 1,
	                        "configVersion" : 1
	                }
	        ],
	        "ok" : 1
	}
	sh0:PRIMARY>
	bye

分片二:

	$ mongo --port 27011
	MongoDB shell version: 3.0.6
	connecting to: 127.0.0.1:27011/test
	> use admin
	switched to db admin
	> cfg={_id:"sh1", members:[ {_id:0,host:"172.30.2.201:27011"}, {_id:1,host:"172.30.2.202:27011"}, {_id:2,host:"172.30.2.203:27011"} ] }
	{
	        "_id" : "sh1",
	        "members" : [
	                {
	                        "_id" : 0,
	                        "host" : "172.30.2.201:27011"
	                },
	                {
	                        "_id" : 1,
	                        "host" : "172.30.2.202:27011"
	                },
	                {
	                        "_id" : 2,
	                        "host" : "172.30.2.203:27011"
	                }
	        ]
	}
	> rs.initiate( cfg );
	{ "ok" : 1 }
	sh1:OTHER> rs.status();
	{
	        "set" : "sh1",
	        "date" : ISODate("2015-10-23T05:36:02.365Z"),
	        "myState" : 1,
	        "members" : [
	                {
	                        "_id" : 0,
	                        "name" : "172.30.2.201:27011",
	                        "health" : 1,
	                        "state" : 1,
	                        "stateStr" : "PRIMARY",
	                        "uptime" : 406,
	                        "optime" : Timestamp(1445578557, 1),
	                        "optimeDate" : ISODate("2015-10-23T05:35:57Z"),
	                        "electionTime" : Timestamp(1445578561, 1),
	                        "electionDate" : ISODate("2015-10-23T05:36:01Z"),
	                        "configVersion" : 1,
	                        "self" : true
	                },
	                {
	                        "_id" : 1,
	                        "name" : "172.30.2.202:27011",
	                        "health" : 1,
	                        "state" : 5,
	                        "stateStr" : "STARTUP2",
	                        "uptime" : 5,
	                        "optime" : Timestamp(0, 0),
	                        "optimeDate" : ISODate("1970-01-01T00:00:00Z"),
	                        "lastHeartbeat" : ISODate("2015-10-23T05:36:01.168Z"),
	                        "lastHeartbeatRecv" : ISODate("2015-10-23T05:36:01.175Z"),
	                        "pingMs" : 0,
	                        "configVersion" : 1
	                },
	                {
	                        "_id" : 2,
	                        "name" : "172.30.2.203:27011",
	                        "health" : 1,
	                        "state" : 5,
	                        "stateStr" : "STARTUP2",
	                        "uptime" : 5,
	                        "optime" : Timestamp(0, 0),
	                        "optimeDate" : ISODate("1970-01-01T00:00:00Z"),
	                        "lastHeartbeat" : ISODate("2015-10-23T05:36:01.167Z"),
	                        "lastHeartbeatRecv" : ISODate("2015-10-23T05:36:01.172Z"),
	                        "pingMs" : 0,
	                        "configVersion" : 1
	                }
	        ],
	        "ok" : 1
	}
	sh1:PRIMARY>
	bye

# 6. 配置分片

	$ mongo --port 30000
	MongoDB shell version: 3.0.6
	connecting to: 127.0.0.1:30000/test
	mongos> use admin;
	switched to db admin
	mongos> sh.addShard("sh0/172.30.2.201:27010,172.30.2.202:27010,172.30.2.203:27010");
	{ "shardAdded" : "sh0", "ok" : 1 }
	mongos> sh.addShard("sh1/172.30.2.201:27011,172.30.2.202:27011,172.30.2.203:27011");
	{ "shardAdded" : "sh1", "ok" : 1 }
	mongos> use mydb;
	switched to db mydb
	mongos> db.createCollection("test");
	{
	        "ok" : 1,
	        "$gleStats" : {
	                "lastOpTime" : Timestamp(1444358911, 1),
	                "electionId" : ObjectId("56172a4bc03d9b1667f8e928")
	        }
	}
	mongos> sh.enableSharding("mydb");
	{ "ok" : 1 }
	mongos> sh.shardCollection("mydb.test", {"_id":1});
	{ "collectionsharded" : "mydb.test", "ok" : 1 }
	mongos> sh.status();
	--- Sharding Status ---
	  sharding version: {
	        "_id" : 1,
	        "minCompatibleVersion" : 5,
	        "currentVersion" : 6,
	        "clusterId" : ObjectId("561728b4030ea038bcb57fa0")
	}
	  shards:
	        {  "_id" : "sh0",  "host" : "sh0/172.30.2.201:27010,172.30.2.202:27010,172.30.2.203:27010" }
	        {  "_id" : "sh1",  "host" : "sh1/172.30.2.201:27011,172.30.2.202:27011,172.30.2.203:27011" }
	  balancer:
	        Currently enabled:  yes
	        Currently running:  no
	        Failed balancer rounds in last 5 attempts:  0
	        Migration Results for the last 24 hours:
	                No recent migrations
	  databases:
	        {  "_id" : "admin",  "partitioned" : false,  "primary" : "config" }
	        {  "_id" : "mydb",  "partitioned" : true,  "primary" : "sh0" }
	                mydb.test
	                        shard key: { "_id" : 1 }
	                        chunks:
	                                sh0     1
	                        { "_id" : { "$minKey" : 1 } } -->> { "_id" : { "$maxKey" : 1 } } on : sh0 Timestamp(1, 0)

可见分片已经配置完成了

# 7. 添加开机启动项

	$ sudo vim /etc/rc.local
	ulimit -SHn 65535
	/opt/mongodb/bin/mongod --config /data/mongodb/sh0/conf/mongodb.conf
	/opt/mongodb/bin/mongod --config /data/mongodb/sh1/conf/mongodb.conf
	/opt/mongodb/bin/mongod --config /data/mongodb/cf0/conf/config.conf
	/opt/mongodb/bin/mongos --config /data/mongodb/ms0/conf/mongos.conf

# 8. 备注

    虽然也是 3 台机器，使用分片的好处是可以把两个分片的 primary 设置在不同的节点，这个可以分摊单节点的压力，当然有更多机器就可以把分片放到不同机器上。
